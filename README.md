# AgentAI Doc Analyzer: RAG-Powered Document Chatbot

AgentAI Doc Analyzer is a full-stack, AI-driven document analysis chatbot built on a **Retrieval-Augmented Generation (RAG)** architecture. It enables users to upload documents and ask natural-language questions, receiving **accurate, context-grounded answers** generated by **GPT-5**, even across large and complex document collections.

This project demonstrates modern **agent-style orchestration**, combining vector search, semantic chunking, tool routing, and LLM reasoning into a scalable, production-ready system.

---

## üöÄ Key Features

- **RAG-Based Question Answering**  
  Retrieves relevant document context before generation to ensure answers are grounded in source data.

- **GPT-5 Integration**  
  Produces high-quality, multi-step reasoning responses with long-context support (up to 16k tokens).

- **Semantic Search at Scale**  
  Vector embeddings with semantic chunking enable similarity search across **50,000+ document segments** with sub-second retrieval.

- **Agent-Style Tool Orchestration**  
  Implements the **Model Context Protocol (MCP)** to standardize communication between:
  - RAG pipeline  
  - Web search tools (SerpAPI)  
  - Vector stores and document loaders  

- **Interactive Chat Interface**  
  Maintains conversational context for follow-up questions and iterative exploration.

- **Scalable Backend Services**  
  Express.js microservices handle ingestion, embedding, querying, and rate-limiting for **500+ concurrent users**.

---

## üß† Architecture Overview

User Query  
‚Üì  
Chat UI (React)  
‚Üì  
API Gateway (Node.js / Express)  
‚Üì  
Agent Router (MCP)  
‚îú‚îÄ‚îÄ Vector Search (Pinecone)  
‚îú‚îÄ‚îÄ Web Search (SerpAPI)  
‚îî‚îÄ‚îÄ Context Assembly  
‚Üì  
GPT-5 Generation  
‚Üì  
Grounded Answer Response  

The system retrieves only the most relevant document context before generation, dramatically improving accuracy and reducing hallucinations compared to traditional LLM chatbots.

---

## üõ† Tech Stack

| Layer | Technology |
|-----|-----------|
| Frontend | React, Ant Design |
| Backend | Node.js, Express |
| LLM | OpenAI GPT-5 |
| RAG Framework | LangChain |
| Vector Store | Pinecone |
| Tool Orchestration | Model Context Protocol (MCP) |
| Search | SerpAPI |
| Deployment | Cloud-ready (Docker-friendly) |

---

## üì¶ Getting Started

### Prerequisites

- Node.js (v18+)
- OpenAI API key
- Pinecone account
- SerpAPI key (optional, for web search)

---

### Clone the Repository

```bash
git clone https://github.com/yunbo2614/AgentAIDocAnalyzer.git
cd AgentAIDocAnalyzer
```

## ‚öôÔ∏è Environment Configuration & Running the Application

Create a `.env` file in the backend directory and configure the following environment variables:

    # Server
    PORT=8080
    ENV=development

    # Authentication
    JWT_SECRET=your_jwt_secret
    JWT_REFRESH_SECRET=your_refresh_token_secret
    JWT_ACCESS_EXPIRATION=15m
    JWT_REFRESH_EXPIRATION=7d

    # Database
    DATABASE_URL=your_database_connection_string

    # Redis Cache
    REDIS_URL=redis://localhost:6379

    # Elasticsearch
    ELASTICSEARCH_URL=http://localhost:9200
    ELASTICSEARCH_USERNAME=your_es_username
    ELASTICSEARCH_PASSWORD=your_es_password

    # AI Image Generation
    OPENAI_API_KEY=your_openai_api_key
    DALLE_MODEL=dall-e-3

    # Google Cloud
    GCP_PROJECT_ID=your_gcp_project_id
    GCP_APP_ENGINE_SERVICE=default

Start the backend services:

    go run main.go

Start the frontend:

    cd frontend
    npm start

The application will be available at:

    http://localhost:3000
